AUROC=0.7509287925696595	AUPRC=0.6198429314362056	Accuracy=0.6976744186046512	MCC=0.30049838203521023	Recall=0.5882352941176471	Precision=0.4444444444444444	f1_score=0.5063291139240507

######NOTE#######
#According to help_documentation of sklearn.metrics.classification_report:in binary classification, recall of the positive class is also known as sensitivity; recall of the negative class is specificity#

              precision    recall  f1-score   support

     control       0.83      0.74      0.78        95
        case       0.44      0.59      0.51        34

    accuracy                           0.70       129
   macro avg       0.64      0.66      0.64       129
weighted avg       0.73      0.70      0.71       129
