AUROC=0.768266253869969	AUPRC=0.6114361809111056	Accuracy=0.7441860465116279	MCC=0.3981380814347516	Recall=0.6470588235294118	Precision=0.5116279069767442	f1_score=0.5714285714285714

######NOTE#######
#According to help_documentation of sklearn.metrics.classification_report:in binary classification, recall of the positive class is also known as sensitivity; recall of the negative class is specificity#

              precision    recall  f1-score   support

     control       0.86      0.78      0.82        95
        case       0.51      0.65      0.57        34

    accuracy                           0.74       129
   macro avg       0.69      0.71      0.69       129
weighted avg       0.77      0.74      0.75       129
