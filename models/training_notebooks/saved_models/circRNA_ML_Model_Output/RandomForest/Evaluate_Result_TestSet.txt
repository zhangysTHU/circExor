AUROC=0.6902476780185759	AUPRC=0.5475606199160887	Accuracy=0.7751937984496124	MCC=0.36490670619755555	Recall=0.4117647058823529	Precision=0.6086956521739131	f1_score=0.49122807017543857

######NOTE#######
#According to help_documentation of sklearn.metrics.classification_report:in binary classification, recall of the positive class is also known as sensitivity; recall of the negative class is specificity#

              precision    recall  f1-score   support

     control       0.81      0.91      0.86        95
        case       0.61      0.41      0.49        34

    accuracy                           0.78       129
   macro avg       0.71      0.66      0.67       129
weighted avg       0.76      0.78      0.76       129
